{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0QRNj3PCxQUVxF0scE8px",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gaurav-bhandari-rgb/Stock-Fuse/blob/main/StockFuse.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Time Series Forecasting**\n",
        "Time series data is recorded at regular time intervals, and the order of these data points is important. Therefore, any predictive model based on time series data will have time as an independent variable. The output of a model would be the predicted value or classification at a specific time. We use stock price data over a period of three years as a time series to predict the future price of those shares.\n"
      ],
      "metadata": {
        "id": "j92l2XE7MAMv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBwf9KI06iJ7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Flatten\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "!pip install yfinance \n",
        "import yfinance as yf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Loading**\n",
        "We use ticker method to retrieve the data from Yahoo Finance website. In another approach we use the existing dataset that contains stock prices for over a period of 6 months for all the banks under Bank Nifty."
      ],
      "metadata": {
        "id": "LWYZ0q4kMpk0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df= yf.Ticker(\"^NSEBANK\").history(period='3y').reset_index()\n",
        "df_axis= yf.Ticker(\"AXISBANK.NS\").history(period='3y').reset_index()\n",
        "df_sbi= yf.Ticker(\"SBIN.NS\").history(period='3y').reset_index()\n",
        "df_rbl= yf.Ticker(\"RBLBANK.NS\").history(period='3y').reset_index()\n",
        "df_pnb= yf.Ticker(\"PNB.NS\").history(period='3y').reset_index()\n",
        "df_kot= yf.Ticker(\"KOTAKBANK.NS\").history(period='3y').reset_index()\n",
        "df_ind= yf.Ticker(\"INDUSINDBK.NS\").history(period='3y').reset_index()\n",
        "df_idfc= yf.Ticker(\"IDFCFIRSTB.NS\").history(period='3y').reset_index()\n",
        "df_icic= yf.Ticker(\"ICICIBANK.NS\").history(period='3y').reset_index()\n",
        "df_band= yf.Ticker(\"BANDHANBNK.NS\").history(period='3y').reset_index()\n",
        "df_hdfc= yf.Ticker(\"HDFC.NS\").history(period='3y').reset_index()\n",
        "df_fed= yf.Ticker(\"FEDERALBNK.NS\").history(period='3y').reset_index()\n",
        "df_au= yf.Ticker(\"AUBANK.NS\").history(period='3y').reset_index()"
      ],
      "metadata": {
        "id": "643OamOEF9ak"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "Tlb7F0a_GNax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Visualizations**"
      ],
      "metadata": {
        "id": "xWP2UmVoNV_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "fig = px.line(df, x='Date', y=\"Open\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "pXQp1ukyGRPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_rbl.Date.max())\n",
        "print(df_rbl.Date.min())"
      ],
      "metadata": {
        "id": "wYdjXW3gGY6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(6, 2, sharex=True, figsize=(20,32))\n",
        "plt.grid(True)\n",
        "sns.lineplot(ax=axes[0, 0], data=df_axis, x='Date', y='Open')\n",
        "axes[0,0].set_title('axis')\n",
        "sns.lineplot(ax=axes[0, 1], data=df_sbi, x='Date', y='Open')\n",
        "axes[0,1].set_title('sbi')\n",
        "sns.lineplot(ax=axes[1, 0], data=df_rbl, x='Date', y='Open')\n",
        "axes[1,0].set_title('rbl')\n",
        "sns.lineplot(ax=axes[1, 1], data=df_pnb, x='Date', y='Open')\n",
        "axes[1,1].set_title('pnb')\n",
        "sns.lineplot(ax=axes[2, 0], data=df_kot, x='Date', y='Open')\n",
        "axes[2,0].set_title('kot')\n",
        "sns.lineplot(ax=axes[2, 1], data=df_ind, x='Date', y='Open')\n",
        "axes[2,1].set_title('ind')\n",
        "sns.lineplot(ax=axes[3, 0], data=df_idfc, x='Date', y='Open')\n",
        "axes[3,0].set_title('idfc')\n",
        "sns.lineplot(ax=axes[3, 1], data=df_icic, x='Date', y='Open')\n",
        "axes[3,1].set_title('icic')\n",
        "sns.lineplot(ax=axes[4, 0], data=df_band, x='Date', y='Open')\n",
        "axes[4,0].set_title('band')\n",
        "sns.lineplot(ax=axes[4, 1], data=df_hdfc, x='Date', y='Open')\n",
        "axes[4,1].set_title('hdfc')\n",
        "sns.lineplot(ax=axes[5, 0], data=df_fed, x='Date', y='Open')\n",
        "axes[5,0].set_title('fed')\n",
        "sns.lineplot(ax=axes[5,1], data=df_au, x='Date', y='Open')\n",
        "axes[5,1].set_title('au')"
      ],
      "metadata": {
        "id": "s2ihZa6dGhUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)\n",
        "date_train=pd.to_datetime(df['Date'])\n",
        "date_train"
      ],
      "metadata": {
        "id": "0FOfXPTkGxeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Scale=StandardScaler()\n",
        "def data_prep(df, lookback, future, Scale):\n",
        "    date_train=pd.to_datetime(df['Date'])\n",
        "    df_train=df[['Open','High','Low','Close','Volume','Dividends','Stock Splits']]\n",
        "    df_train=df_train.astype(float)\n",
        "    \n",
        "    df_train_scaled=Scale.fit_transform(df_train)\n",
        "\n",
        "    X, y =[],[]\n",
        "    for i in range(lookback, len(df_train_scaled)-future+1):\n",
        "        X.append(df_train_scaled[i-lookback:i, 0:df_train.shape[1]])\n",
        "        y.append(df_train_scaled[i+future-1:i+future, 0])\n",
        "        \n",
        "    return np.array(X), np.array(y), df_train, date_train\n",
        "\n",
        "Lstm_x, Lstm_y, df_train, date_train = data_prep(df, 30, 1, Scale)"
      ],
      "metadata": {
        "id": "3RnG9HBLHIzt"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *LSTM*\n",
        "\n",
        "LSTMs are very powerful in sequence prediction problems because theyâ€™re able to store past information. This is important in our case because the previous\n",
        "price of a stock is crucial in predicting its future price.\n",
        "\n",
        "Long-Short-Term Memory Recurrent Neural Network belongs to the family of deep learning algorithms. It is a recurrent network because of the feedback connections in its architecture. It has an advantage over traditional neural networks due to its capability to process the entire sequence of data. Its architecture comprises the cell, input gate, output gate and forget gate.\n",
        "\n",
        "The input gate: The input gate adds information to the cell state, The forget gate: It removes the information that is no longer required by the model, The output gate: Output Gate at LSTM selects the information to be shown as output.\n",
        "\n",
        "While Implementing any LSTM, we should always reshape our X train in 3-D, add 1 the reason behind is the time step and the 1 is given to the LSTM."
      ],
      "metadata": {
        "id": "8ZOv1wt-NvP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Lstm_fallback(X,y):\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(LSTM(64, activation='relu',input_shape=(X.shape[1], X.shape[2]),  return_sequences=True))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LSTM(32, activation='relu', return_sequences=False))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(y.shape[1], activation='relu'))\n",
        "\n",
        "    opt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)  \n",
        "    model.compile(\n",
        "            loss='mse',\n",
        "            optimizer=opt,\n",
        "        )\n",
        "    \n",
        "    es = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=15, restore_best_weights=True)\n",
        "    model.fit(X, y, epochs=100, verbose=1, callbacks=[es], validation_split=0.1, batch_size=16)\n",
        "    return model"
      ],
      "metadata": {
        "id": "fAKYeHMMHVKk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Lstm_model1(X, y):\n",
        "    regressor = Sequential()\n",
        "\n",
        "    regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X.shape[1], X.shape[2])))\n",
        "    regressor.add(Dropout(0.2))\n",
        "    regressor.add(LSTM(units = 50, return_sequences = True))\n",
        "    regressor.add(Dropout(0.2))\n",
        "    regressor.add(LSTM(units = 50, return_sequences = True))\n",
        "    regressor.add(Dropout(0.2))\n",
        "    regressor.add(LSTM(units = 50))\n",
        "    regressor.add(Dropout(0.2))\n",
        "    regressor.add(Dense(units = 1))\n",
        "\n",
        "    regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
        "    \n",
        "    es = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=15, restore_best_weights=True)\n",
        "    regressor.fit(X, y, epochs = 100, validation_split=0.1, batch_size = 64, verbose=1, callbacks=[es])\n",
        "    return regressor"
      ],
      "metadata": {
        "id": "jbKv1eH3Ha6k"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Lstm_model2(X,y):\n",
        "    model=Sequential()\n",
        "    \n",
        "    model.add(LSTM(20,return_sequences=True,input_shape=(X.shape[1], X.shape[2])))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(BatchNormalization())\n",
        "    #model.add(LSTM(15,return_sequences=True))\n",
        "    #model.add(Dropout(0.2))\n",
        "    #model.add(BatchNormalization())\n",
        "    model.add(LSTM(15))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(16, activation='relu'))\n",
        "    model.add(Dense(1))\n",
        "    \n",
        "    adam = optimizers.Adam(0.001)\n",
        "    model.compile(loss='mean_squared_error',optimizer=adam)\n",
        "    \n",
        "    es = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=15, restore_best_weights=True)\n",
        "    model.fit(X, y,validation_split=0.2,epochs=100,batch_size=64,verbose=1, callbacks=[es])\n",
        "    return model"
      ],
      "metadata": {
        "id": "4RQ2HZM3HgWZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Prediction**"
      ],
      "metadata": {
        "id": "uCUJV7JWObQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_open(model,date_train,Lstm_x,df_train, future, Scale):\n",
        "    forecasting_dates=pd.date_range(list(date_train)[-1], periods=future, freq='1d').tolist()\n",
        "    predicted=model.predict(Lstm_x[-future:])\n",
        "    predicted1=np.repeat(predicted, df_train.shape[1], axis=-1)\n",
        "    predicted_descaled=Scale.inverse_transform(predicted1)[:,0]\n",
        "    return predicted_descaled,forecasting_dates\n",
        "\n",
        "def output_prep(forecasting_dates,predicted_descaled):\n",
        "    dates=[]\n",
        "    for i in forecasting_dates:\n",
        "        dates.append(i.date())\n",
        "    df_final=pd.DataFrame(columns=['Date','Open'])\n",
        "    df_final['Date']=pd.to_datetime(dates)\n",
        "    df_final['Open']=predicted_descaled\n",
        "    return df_final"
      ],
      "metadata": {
        "id": "1GASyBGzHlBD"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def results(df, lookback, future, Scale, x):\n",
        "    Lstm_x, Lstm_y, df_train, date_train = data_prep(df, lookback, future, Scale)\n",
        "    model=Lstm_model1(Lstm_x,Lstm_y)\n",
        "    loss=pd.DataFrame(model.history.history)\n",
        "    loss.plot()\n",
        "    future=30\n",
        "    predicted_descaled,forecasting_dates=predict_open(model,date_train,Lstm_x,df_train,future, Scale)\n",
        "    results=output_prep(forecasting_dates,predicted_descaled)   \n",
        "    print(results.head())\n",
        "    plt.show()\n",
        "    fig = px.area(results, x=\"Date\", y=\"Open\", title=x)\n",
        "    fig.update_yaxes(range=[results.Open.min()-10, results.Open.max()+10])\n",
        "    fig.show()"
      ],
      "metadata": {
        "id": "Wptdicx_HpGS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def results1(df, lookback, future, Scale, x):\n",
        "    Lstm_x, Lstm_y, df_train, date_train = data_prep(df, lookback, future, Scale)\n",
        "    model=Lstm_model2(Lstm_x,Lstm_y)\n",
        "    loss=pd.DataFrame(model.history.history)\n",
        "    loss.plot()\n",
        "    future=30\n",
        "    predicted_descaled,forecasting_dates=predict_open(model,date_train,Lstm_x,df_train,future, Scale)\n",
        "    results=output_prep(forecasting_dates,predicted_descaled)   \n",
        "    print(results.head())\n",
        "    plt.show()\n",
        "    fig = px.area(results, x=\"Date\", y=\"Open\", title=x)\n",
        "    fig.update_yaxes(range=[results.Open.min()-10, results.Open.max()+10])\n",
        "    fig.show()"
      ],
      "metadata": {
        "id": "n_4IrFw5HulA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Result Visualization**"
      ],
      "metadata": {
        "id": "ymIEbNeYOfMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results(df, 30, 1, Scale, 'NSEBANK')"
      ],
      "metadata": {
        "id": "IRGfwNIxH2s-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results1(df, 30, 1, Scale, 'NSEBANK')"
      ],
      "metadata": {
        "id": "qvm2lcjdIPTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d={'AXIS':df_axis, 'SBI':df_sbi, 'RBL': df_rbl ,'PNB': df_pnb ,'KOTAK': df_kot, \n",
        "   'INDUSIND':df_ind, 'IDFC': df_idfc, 'ICIC': df_icic , 'BANDHAN': df_band, 'HDFC': df_hdfc, 'FEDERAL': df_fed,\n",
        "   'AU FIN':df_au}\n",
        "\n",
        "for x in d.keys():\n",
        "    results1(d[x], 30, 1, Scale, x)"
      ],
      "metadata": {
        "id": "KBUMduX-IRMa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}